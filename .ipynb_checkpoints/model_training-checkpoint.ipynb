{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "mexican-private",
   "metadata": {},
   "source": [
    "# Model Training Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "anonymous-spouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from IPython.core.display import display, HTML\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# repeatable functions housed in the utils file and imported here\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manual-rebecca",
   "metadata": {},
   "source": [
    "## Create Training and Validation Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interesting-rouge",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/42755214/how-to-keep-numpy-array-when-saving-pandas-dataframe-to-csv is where I got the converter code from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "exact-month",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import numpy as np\n",
    "def from_np_array(array_string):\n",
    "    array_string = ','.join(array_string.replace('[ ', '[').split())\n",
    "    return np.array(ast.literal_eval(array_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "indirect-episode",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('./datasets/annotations_map.csv', converters={'new_bb': from_np_array})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "color-saturday",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.reset_index()\n",
    "\n",
    "X = df_train[['new_path','new_bb']]\n",
    "Y = df_train['class']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "streaming-christopher",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = WaldoDataset(X_train['new_path'],X_train['new_bb'] ,y_train)\n",
    "valid_ds = WaldoDataset(X_val['new_path'],X_val['new_bb'],y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "simplified-corpus",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "amateur-green",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 500, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imread('./images_resized/2.jpg').shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "third-latino",
   "metadata": {},
   "source": [
    "## Building Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "recovered-evans",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \n",
    "    ## Initialization of the model\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        ## Conv2d(in_channels, out_channels, kernel_size, stride)\n",
    "        self.conv1 = nn.Conv2d(3, 32, 100, stride=10) \n",
    "        self.pool = nn.MaxPool2d(5, 2) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear= nn.Linear(11552, 4)\n",
    "    \n",
    "    ## Defining the forward function\n",
    "    def forward(self, x):\n",
    "        \n",
    "        batch_size= x.shape[0]\n",
    "        channel= x.shape[3]\n",
    "        h= x.shape[1]\n",
    "        w= x.shape[2]\n",
    "        \n",
    "        x= x.reshape(batch_size, channel, h, w)\n",
    "        \n",
    "        output = self.conv1(x)\n",
    "        output = self.pool(output)\n",
    "        output = self.relu(output)\n",
    "        output = output.reshape(batch_size, 11552)\n",
    "        output = self.linear(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imposed-double",
   "metadata": {},
   "source": [
    "# Train the Model\n",
    "\n",
    "\n",
    "- Structured similarly to main.py file from pytorch part of A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "federal-vessel",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define Hyperparameters -- Currently setting values that we can modify\n",
    "\n",
    "loss_type = \"l1\"\n",
    "learning_rate = 1e-5\n",
    "momentum = 0.9\n",
    "reg = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "humanitarian-destruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Criterion - Loss Function\n",
    "if loss_type == \"CE\":\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "if loss_type == \"l1\":\n",
    "    criterion = nn.L1Loss()\n",
    "    \n",
    "if loss_type == \"l2\":\n",
    "    criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "basic-addiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "wired-cannon",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), learning_rate,\n",
    "                            momentum=momentum,\n",
    "                            weight_decay=reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "intended-soundtrack",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epocs(model, optimizer, train_dl, epochs=10):\n",
    "    idx = 0\n",
    "    model= model.float()\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        sum_loss = 0\n",
    "        for x, y_bb in train_dl:\n",
    "            x= x.float()\n",
    "            out_bb = model(x)\n",
    "            \n",
    "            y_bb = torch.tensor(y_bb)\n",
    "            \n",
    "            ## out_bb and y_bb are in different formats - the need to both be tensors I think.\n",
    "            ## this means we'll need to update the resize_image_bb to save the new_bb as a tensor instead of a list, I think\n",
    "            loss= F.l1_loss(out_bb, y_bb)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            idx += 1\n",
    "            sum_loss += loss.item()\n",
    "        train_loss = sum_loss\n",
    "        print(\"Training Loss for epoch {0}: {1}\".format(i,train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "monetary-kenya",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-30-687a9ae9e251>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_bb = torch.tensor(y_bb)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss for epoch 0: 1510.3412475585938\n",
      "Training Loss for epoch 1: 1497.4430847167969\n",
      "Training Loss for epoch 2: 1485.1582641601562\n",
      "Training Loss for epoch 3: 1455.7224731445312\n",
      "Training Loss for epoch 4: 1443.0083770751953\n"
     ]
    }
   ],
   "source": [
    "train_epocs(model= model, optimizer= optimizer, train_dl= train_dl, epochs= 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mysterious-palestinian",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
