{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "exempt-equity",
   "metadata": {},
   "source": [
    "# Model Training Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "oriental-street",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from IPython.core.display import display, HTML\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import ast\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# repeatable functions housed in the utils file and imported here\n",
    "from utils import *\n",
    "from model_training_utils import train as training_loop\n",
    "from model_training_utils import validate as validation_loop\n",
    "from model_training_utils import hp_grid_search\n",
    "from models import CNN\n",
    "from models import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brazilian-namibia",
   "metadata": {},
   "source": [
    "## Create Training and Validation Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "indoor-weekend",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('./datasets/annotations_map.csv', converters={'new_bb': from_np_array})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "desperate-sunrise",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training observations:  32\n",
      "Number of validation observations:  11\n"
     ]
    }
   ],
   "source": [
    "df_train = df.reset_index()\n",
    "X = df_train[['new_path','new_bb']]\n",
    "Y = df_train['class']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size=0.25, random_state=42)\n",
    "print('Number of training observations: ', X_train.shape[0])\n",
    "print('Number of validation observations: ', X_val.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proprietary-interstate",
   "metadata": {},
   "source": [
    "## Build RCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaded-monitoring",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "international-domestic",
   "metadata": {},
   "source": [
    "## Build YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earned-catch",
   "metadata": {},
   "source": [
    "#### The Design of the YOLO NN was taken from the following paper:\n",
    "\n",
    "https://arxiv.org/pdf/1506.02640.pdf - \"You Only Look Once: Unified, Real-Time Object Detection\" by Redmon, Divvala, Girshick, and Farhadi\n",
    "\n",
    "The following article is YOLO V2:\n",
    "https://arxiv.org/pdf/1612.08242v1.pdf - \"YOLO 9000: Better, Faster, Stronger\" by Redmon, and Farhadi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "radical-tiffany",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLO(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(YOLO, self).__init__()\n",
    "        \n",
    "        # First\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, 1, padding=1)\n",
    "        self.pooling = nn.AvgPool2d(2, 2)\n",
    "        \n",
    "        # Second\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1, padding=1)\n",
    "        \n",
    "        # Third\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, 1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 64, 1, 1)\n",
    "        \n",
    "        # Fourth\n",
    "        self.conv5 = nn.Conv2d(128, 256, 3, 1, padding=1)\n",
    "        self.conv6 = nn.Conv2d(256, 128, 1, 1)\n",
    "        \n",
    "        # Fifth\n",
    "        self.conv7 = nn.Conv2d(256, 512, 3, 1, padding=1)\n",
    "        self.conv8 = nn.Conv2d(512, 256, 1, 1)\n",
    "        \n",
    "        # Sixth\n",
    "        self.conv9 = nn.Conv2d(512, 1024, 3, 1, padding=1)\n",
    "        self.conv10 = nn.Conv2d(1024, 512, 1, 1)\n",
    "        \n",
    "        # Final\n",
    "        self.conv11 = nn.Conv2d(1024, 1000, 1, 1)\n",
    "        \n",
    "        # FC Layer and Softmax\n",
    "        self.FC = nn.Linear(1000, 4)\n",
    "        \n",
    "        \n",
    "            \n",
    "    def forward(self, x):\n",
    "        \n",
    "        batch_size, h, w, channel = x.shape\n",
    "        x= x.reshape(batch_size, channel, h, w)\n",
    "        \n",
    "        output = self.conv1(x) # 500\n",
    "        output = self.pooling(output) # 250\n",
    "        \n",
    "        output = self.conv2(output) # 250\n",
    "        output = self.pooling(output) # 125\n",
    "        \n",
    "        output = self.conv3(output) # 125\n",
    "        output = self.conv4(output) # 125\n",
    "        output = self.conv3(output) # 125\n",
    "        output = self.pooling(output) # 62\n",
    "        \n",
    "        output = self.conv5(output) # 62\n",
    "        output = self.conv6(output) # 62\n",
    "        output = self.conv5(output) # 62\n",
    "        output = self.pooling(output) # 31\n",
    "        \n",
    "        output = self.conv7(output) # 31\n",
    "        output = self.conv8(output) # 31\n",
    "        output = self.conv7(output) # 31\n",
    "        output = self.conv8(output) # 31\n",
    "        output = self.conv7(output) # 31\n",
    "        output = self.pooling(output) # 15\n",
    "        \n",
    "        output = self.conv9(output) # 15\n",
    "        output = self.conv10(output) # 15\n",
    "        output = self.conv9(output) # 15\n",
    "        output = self.conv10(output) # 15\n",
    "        output = self.conv9(output) # 15\n",
    "        \n",
    "        output = self.conv11(output)\n",
    "        output = output.mean([2, 3])\n",
    "        \n",
    "        output = self.FC(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chicken-export",
   "metadata": {},
   "source": [
    "# Train the Model\n",
    "\n",
    "\n",
    "- Structured similarly to main.py file from pytorch part of A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "furnished-haiti",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define Hyperparameters -- Currently setting values that we can modify\n",
    "loss_type = \"l1\"\n",
    "learning_rate = 0.001\n",
    "momentum = 0.5\n",
    "reg = 1e-2\n",
    "\n",
    "training_batch_size= 5\n",
    "validation_batch_size= 5\n",
    "\n",
    "model= \"YOLO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bottom-solution",
   "metadata": {},
   "outputs": [],
   "source": [
    "if loss_type == \"l1\":\n",
    "    criterion = nn.L1Loss()\n",
    "    \n",
    "if loss_type == \"l2\":\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "if model== \"SimpleCNN\":\n",
    "    model= CNN()\n",
    "elif model == \"YOLO\":\n",
    "    model = YOLO()\n",
    "    \n",
    "train_ds = WaldoDataset(X_train['new_path'],X_train['new_bb'] ,y_train)\n",
    "valid_ds = WaldoDataset(X_val['new_path'],X_val['new_bb'],y_val)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=training_batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=validation_batch_size)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), learning_rate,\n",
    "                            momentum=momentum,\n",
    "                            weight_decay=reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "super-hollow",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([2, 4])\n",
      " \n",
      "--------------------------------------------------------\n",
      "Training Loss for Epoch 0: 1505.1929473876953\n",
      "Output:  torch.Size([5, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anandsongvit/CS7643/Final Project/CS7643-Final-Project/model_training_utils.py:71: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_bb= torch.tensor(y_bb)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([1, 4])\n",
      "Validation Loss for Epoch 0: 617.2049713134766\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([2, 4])\n",
      " \n",
      "--------------------------------------------------------\n",
      "Training Loss for Epoch 1: 1532.519790649414\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([1, 4])\n",
      "Validation Loss for Epoch 1: 617.1839294433594\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([2, 4])\n",
      " \n",
      "--------------------------------------------------------\n",
      "Training Loss for Epoch 2: 1525.0445861816406\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([1, 4])\n",
      "Validation Loss for Epoch 2: 617.1627807617188\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([2, 4])\n",
      " \n",
      "--------------------------------------------------------\n",
      "Training Loss for Epoch 3: 1527.4691772460938\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([1, 4])\n",
      "Validation Loss for Epoch 3: 617.1416320800781\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([2, 4])\n",
      " \n",
      "--------------------------------------------------------\n",
      "Training Loss for Epoch 4: 1544.5939331054688\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([1, 4])\n",
      "Validation Loss for Epoch 4: 617.1204071044922\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([2, 4])\n",
      " \n",
      "--------------------------------------------------------\n",
      "Training Loss for Epoch 5: 1552.718490600586\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([1, 4])\n",
      "Validation Loss for Epoch 5: 617.0991821289062\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([2, 4])\n",
      " \n",
      "--------------------------------------------------------\n",
      "Training Loss for Epoch 6: 1578.242919921875\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([1, 4])\n",
      "Validation Loss for Epoch 6: 617.0779571533203\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([2, 4])\n",
      " \n",
      "--------------------------------------------------------\n",
      "Training Loss for Epoch 7: 1471.1673583984375\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([1, 4])\n",
      "Validation Loss for Epoch 7: 617.0565795898438\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([2, 4])\n",
      " \n",
      "--------------------------------------------------------\n",
      "Training Loss for Epoch 8: 1525.4164276123047\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([1, 4])\n",
      "Validation Loss for Epoch 8: 617.0352478027344\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([2, 4])\n",
      " \n",
      "--------------------------------------------------------\n",
      "Training Loss for Epoch 9: 1505.2655334472656\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([1, 4])\n",
      "Validation Loss for Epoch 9: 617.0137329101562\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([2, 4])\n",
      " \n",
      "--------------------------------------------------------\n",
      "Training Loss for Epoch 10: 1518.0393676757812\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([1, 4])\n",
      "Validation Loss for Epoch 10: 616.9921417236328\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([2, 4])\n",
      " \n",
      "--------------------------------------------------------\n",
      "Training Loss for Epoch 11: 1516.9378967285156\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([1, 4])\n",
      "Validation Loss for Epoch 11: 616.9705047607422\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([2, 4])\n",
      " \n",
      "--------------------------------------------------------\n",
      "Training Loss for Epoch 12: 1469.5612487792969\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([1, 4])\n",
      "Validation Loss for Epoch 12: 616.9486999511719\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([2, 4])\n",
      " \n",
      "--------------------------------------------------------\n",
      "Training Loss for Epoch 13: 1528.6093139648438\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([1, 4])\n",
      "Validation Loss for Epoch 13: 616.9267883300781\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([2, 4])\n",
      " \n",
      "--------------------------------------------------------\n",
      "Training Loss for Epoch 14: 1535.531982421875\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([1, 4])\n",
      "Validation Loss for Epoch 14: 616.9047546386719\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([2, 4])\n",
      " \n",
      "--------------------------------------------------------\n",
      "Training Loss for Epoch 15: 1546.729507446289\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([1, 4])\n",
      "Validation Loss for Epoch 15: 616.882568359375\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([2, 4])\n",
      " \n",
      "--------------------------------------------------------\n",
      "Training Loss for Epoch 16: 1546.0015411376953\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([1, 4])\n",
      "Validation Loss for Epoch 16: 616.8602142333984\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([2, 4])\n",
      " \n",
      "--------------------------------------------------------\n",
      "Training Loss for Epoch 17: 1564.4960174560547\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([1, 4])\n",
      "Validation Loss for Epoch 17: 616.8377380371094\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([2, 4])\n",
      " \n",
      "--------------------------------------------------------\n",
      "Training Loss for Epoch 18: 1532.2453308105469\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([1, 4])\n",
      "Validation Loss for Epoch 18: 616.8153991699219\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([2, 4])\n",
      " \n",
      "--------------------------------------------------------\n",
      "Training Loss for Epoch 19: 1544.2664031982422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([5, 4])\n",
      "Output:  torch.Size([1, 4])\n",
      "Validation Loss for Epoch 19: 616.79248046875\n"
     ]
    }
   ],
   "source": [
    "training_loop(model= model, optimizer = optimizer, train_dl= train_dl, valid_dl=valid_dl, epochs= 20, criterion= criterion, verbose= True, return_loss= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dutch-stable",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_type= [\"l1\"]\n",
    "learning_rate= [0.001,0.0001]\n",
    "momentum = [0.9]\n",
    "reg = [0.01]\n",
    "batch_size= [10]\n",
    "\n",
    "all_training_loss, all_validation_loss= hp_grid_search(model_type= \"SimpleCNN\", \n",
    "               lr_list=learning_rate, \n",
    "               momentum_list=momentum, \n",
    "               reg_list=reg, \n",
    "               batch_size_list=batch_size,\n",
    "               train_ds= train_ds,\n",
    "               valid_ds= valid_ds,\n",
    "               optimizer= optimizer, \n",
    "               loss_type_list=loss_type,\n",
    "               epochs= 10,\n",
    "               save_all_plots=\"Yes\", \n",
    "               save_final_plot=\"Yes\",\n",
    "               final_plot_prefix=\"Test\", \n",
    "               return_all_loss= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earned-greece",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
