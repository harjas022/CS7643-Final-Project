{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "exempt-equity",
   "metadata": {},
   "source": [
    "# Model Training Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "oriental-street",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from IPython.core.display import display, HTML\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import ast\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# repeatable functions housed in the utils file and imported here\n",
    "from utils import *\n",
    "from model_training_utils import train as training_loop\n",
    "from model_training_utils import validate as validation_loop\n",
    "from model_training_utils import hp_grid_search\n",
    "from models import CNN\n",
    "from models import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brazilian-namibia",
   "metadata": {},
   "source": [
    "## Create Training and Validation Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "indoor-weekend",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('./datasets/annotations_map.csv', converters={'new_bb': from_np_array})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "desperate-sunrise",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training observations:  32\n",
      "Number of validation observations:  11\n"
     ]
    }
   ],
   "source": [
    "df_train = df.reset_index()\n",
    "X = df_train[['new_path','new_bb']]\n",
    "Y = df_train['class']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size=0.25, random_state=42)\n",
    "print('Number of training observations: ', X_train.shape[0])\n",
    "print('Number of validation observations: ', X_val.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proprietary-interstate",
   "metadata": {},
   "source": [
    "## Build RCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaded-monitoring",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "international-domestic",
   "metadata": {},
   "source": [
    "## Build YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earned-catch",
   "metadata": {},
   "source": [
    "#### The Design of the YOLO NN was taken from the following paper:\n",
    "\n",
    "https://arxiv.org/pdf/1506.02640.pdf - \"You Only Look Once: Unified, Real-Time Object Detection\" by Redmon, Divvala, Girshick, and Farhadi\n",
    "\n",
    "The following article is YOLO V2:\n",
    "https://arxiv.org/pdf/1612.08242v1.pdf - \"YOLO 9000: Better, Faster, Stronger\" by Redmon, and Farhadi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "radical-tiffany",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLO(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(YOLO, self).__init__()\n",
    "        \n",
    "        # First\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, 1, padding=1)\n",
    "        self.pooling = nn.AvgPool2d(2, 2)\n",
    "        \n",
    "        # Second\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1, padding=1)\n",
    "        \n",
    "        # Third\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, 1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 64, 1, 1)\n",
    "        \n",
    "        # Fourth\n",
    "        self.conv5 = nn.Conv2d(128, 256, 3, 1, padding=1)\n",
    "        self.conv6 = nn.Conv2d(256, 128, 1, 1)\n",
    "        \n",
    "        # Fifth\n",
    "        self.conv7 = nn.Conv2d(256, 512, 3, 1, padding=1)\n",
    "        self.conv8 = nn.Conv2d(512, 256, 1, 1)\n",
    "        \n",
    "        # Sixth\n",
    "        self.conv9 = nn.Conv2d(512, 1024, 3, 1, padding=1)\n",
    "        self.conv10 = nn.Conv2d(1024, 512, 1, 1)\n",
    "        \n",
    "        # Final\n",
    "        self.conv11 = nn.Conv2d(1024, 1000, 1, 1)\n",
    "        self.avgpool = nn.AvgPool2d()\n",
    "        \n",
    "        # FC Layer and Softmax\n",
    "        self.softmax = nn.Softmax()\n",
    "        self.FC = nn.Linear(492032, 4)\n",
    "        \n",
    "        \n",
    "            \n",
    "    def forward(self, x):\n",
    "        \n",
    "        batch_size, h, w, channel = x.shape\n",
    "        x= x.reshape(batch_size, channel, h, w)\n",
    "        \n",
    "        output = self.conv1(x) # 500\n",
    "        output = self.pooling(output) # 250\n",
    "        \n",
    "        output = self.conv2(output) # 250\n",
    "        output = self.pooling(output) # 125\n",
    "        \n",
    "        output = self.conv3(output) # 125\n",
    "        output = self.conv4(output) # 125\n",
    "        output = self.conv3(output) # 125\n",
    "        output = self.pooling(output) # 62\n",
    "        \n",
    "        output = self.conv5(output) # 62\n",
    "        output = self.conv6(output) # 62\n",
    "        output = self.conv5(output) # 62\n",
    "        output = self.pooling(output) # 31\n",
    "        \n",
    "        output = self.conv7(output) # 31\n",
    "        output = self.conv8(output) # 31\n",
    "        output = self.conv7(output) # 31\n",
    "        output = self.conv8(output) # 31\n",
    "        output = self.conv7(output) # 31\n",
    "        output = self.pooling(output) # 15\n",
    "        \n",
    "        output = self.conv9(output) # 15\n",
    "        output = self.conv10(output) # 15\n",
    "        output = self.conv9(output) # 15\n",
    "        output = self.conv10(output) # 15\n",
    "        output = self.conv9(output) # 15\n",
    "        \n",
    "        output = self.conv11(output)\n",
    "        \n",
    "        print(\"Output: \", output.size())\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chicken-export",
   "metadata": {},
   "source": [
    "# Train the Model\n",
    "\n",
    "\n",
    "- Structured similarly to main.py file from pytorch part of A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "furnished-haiti",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define Hyperparameters -- Currently setting values that we can modify\n",
    "loss_type = \"l1\"\n",
    "learning_rate = 0.001\n",
    "momentum = 0.5\n",
    "reg = 1e-2\n",
    "\n",
    "training_batch_size= 5\n",
    "validation_batch_size= 5\n",
    "\n",
    "model= \"YOLO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "bottom-solution",
   "metadata": {},
   "outputs": [],
   "source": [
    "if loss_type == \"l1\":\n",
    "    criterion = nn.L1Loss()\n",
    "    \n",
    "if loss_type == \"l2\":\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "if model== \"SimpleCNN\":\n",
    "    model= CNN()\n",
    "elif model == \"YOLO\":\n",
    "    model = YOLO()\n",
    "    \n",
    "train_ds = WaldoDataset(X_train['new_path'],X_train['new_bb'] ,y_train)\n",
    "valid_ds = WaldoDataset(X_val['new_path'],X_val['new_bb'],y_val)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=training_batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=validation_batch_size)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), learning_rate,\n",
    "                            momentum=momentum,\n",
    "                            weight_decay=reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "super-hollow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:  torch.Size([5, 1000, 15, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anandsongvit/miniconda3/lib/python3.8/site-packages/torch/nn/modules/loss.py:94: UserWarning: Using a target size (torch.Size([5, 4])) that is different to the input size (torch.Size([5, 1000, 15, 15])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (15) must match the size of tensor b (4) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-172-859393e8261a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraining_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_loss\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/CS7643/Final Project/CS7643-Final-Project/model_training_utils.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, train_dl, valid_dl, criterion, epochs, plot, return_loss, verbose)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mout_bb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0my_bb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_bb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_bb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_bb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36ml1_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2633\u001b[0;31m     \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2634\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/functional.py\u001b[0m in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (15) must match the size of tensor b (4) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "training_loop(model= model, optimizer = optimizer, train_dl= train_dl, valid_dl=valid_dl, epochs= 20, criterion= criterion, verbose= True, return_loss= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dutch-stable",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_type= [\"l1\"]\n",
    "learning_rate= [0.001,0.0001]\n",
    "momentum = [0.9]\n",
    "reg = [0.01]\n",
    "batch_size= [10]\n",
    "\n",
    "all_training_loss, all_validation_loss= hp_grid_search(model_type= \"SimpleCNN\", \n",
    "               lr_list=learning_rate, \n",
    "               momentum_list=momentum, \n",
    "               reg_list=reg, \n",
    "               batch_size_list=batch_size,\n",
    "               train_ds= train_ds,\n",
    "               valid_ds= valid_ds,\n",
    "               optimizer= optimizer, \n",
    "               loss_type_list=loss_type,\n",
    "               epochs= 10,\n",
    "               save_all_plots=\"Yes\", \n",
    "               save_final_plot=\"Yes\",\n",
    "               final_plot_prefix=\"Test\", \n",
    "               return_all_loss= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earned-greece",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
