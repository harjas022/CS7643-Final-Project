{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "exempt-equity",
   "metadata": {},
   "source": [
    "# Model Training Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "oriental-street",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from IPython.core.display import display, HTML\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import ast\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# repeatable functions housed in the utils file and imported here\n",
    "from utils import *\n",
    "from model_training_utils import train as training_loop\n",
    "from model_training_utils import validate as validation_loop\n",
    "from model_training_utils import hp_grid_search\n",
    "from models import CNN, YOLO, VGG, PreTrainedVGG, SimpleVGG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brazilian-namibia",
   "metadata": {},
   "source": [
    "## Create Training and Validation Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "indoor-weekend",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('./datasets/annotations_map.csv', converters={'new_bb': from_np_array})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "desperate-sunrise",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of training observations:  32\nNumber of validation observations:  11\n"
     ]
    }
   ],
   "source": [
    "df_train = df.reset_index()\n",
    "X = df_train[['new_path','new_bb']]\n",
    "Y = df_train['class']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size=0.25, random_state=42)\n",
    "print('Number of training observations: ', X_train.shape[0])\n",
    "print('Number of validation observations: ', X_val.shape[0])"
   ]
  },
  {
   "source": [
    "## Build Simple CNN"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_cnn = CNN()"
   ]
  },
  {
   "source": [
    "## Build VGG\n",
    "Implementation of VGG-16 architecture based on https://neurohive.io/en/popular-networks/vgg16/. VGG-16 is known for its high accuracy and speen on object detection tasks, largely attributed to its 3x3 kernel size."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = VGG()"
   ]
  },
  {
   "source": [
    "## Pre-trained VGG\n",
    "A pytorch VGG-16 model that was pre-trained on object identification. Utilized for benchmarking our own implementations against."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preTrainedVGG = PreTrainedVGG()"
   ]
  },
  {
   "source": [
    "## Build Simple VGG\n",
    "Our simplified VGG based model that attempts to achieve better performance by using less layers. The idea behind this was that the many layers and transformations in VGG can cause it to struggle with smaller objects."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_vgg = SimpleVGG()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "international-domestic",
   "metadata": {},
   "source": [
    "## Build YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earned-catch",
   "metadata": {},
   "source": [
    "#### The Design of the YOLO NN was taken from the following paper:\n",
    "\n",
    "https://arxiv.org/pdf/1506.02640.pdf - \"You Only Look Once: Unified, Real-Time Object Detection\" by Redmon, Divvala, Girshick, and Farhadi\n",
    "\n",
    "The following article is YOLO V2:\n",
    "https://arxiv.org/pdf/1612.08242v1.pdf - \"YOLO 9000: Better, Faster, Stronger\" by Redmon, and Farhadi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "radical-tiffany",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo = YOLO()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chicken-export",
   "metadata": {},
   "source": [
    "# Train the Model\n",
    "\n",
    "\n",
    "- Structured similarly to main.py file from pytorch part of A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "furnished-haiti",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define Hyperparameters -- Currently setting values that we can modify\n",
    "loss_type = \"l1\"\n",
    "learning_rate = 0.001\n",
    "momentum = 0.5\n",
    "reg = 1e-2\n",
    "\n",
    "training_batch_size= 40\n",
    "validation_batch_size= 40\n",
    "\n",
    "model= \"VGG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bottom-solution",
   "metadata": {},
   "outputs": [],
   "source": [
    "if loss_type == \"l1\":\n",
    "    criterion = nn.L1Loss()\n",
    "    \n",
    "if loss_type == \"l2\":\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "if model == \"SimpleCNN\":\n",
    "    model = simple_cnn\n",
    "elif model == \"YOLO\":\n",
    "    model = yolo\n",
    "elif model == \"VGG\":\n",
    "    model = vgg\n",
    "elif model == \"PreTrainedVGG\":\n",
    "    model = preTrainedVGG\n",
    "elif model_type == \"SimpleVGG\":\n",
    "    model = simple_vgg\n",
    "    \n",
    "train_ds = WaldoDataset(X_train['new_path'],X_train['new_bb'] ,y_train)\n",
    "valid_ds = WaldoDataset(X_val['new_path'],X_val['new_bb'],y_val)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=training_batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=validation_batch_size)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), learning_rate,\n",
    "                            momentum=momentum,\n",
    "                            weight_decay=reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "super-hollow",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 439\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-859393e8261a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraining_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_loss\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/School/CS7643-DL/CS7643-Final-Project/model_training_utils.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, train_dl, valid_dl, criterion, epochs, plot, return_loss, verbose)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_bb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mout_bb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0my_bb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_bb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_bb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_bb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cs7643-final/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/School/CS7643-DL/CS7643-Final-Project/models/VGG.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_2d_3_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_2d_3_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cs7643-final/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cs7643-final/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cs7643-final/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    417\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 419\u001b[0;31m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0m\u001b[1;32m    420\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_loop(model= model, optimizer = optimizer, train_dl= train_dl, valid_dl=valid_dl, epochs= 20, criterion= criterion, verbose= True, return_loss= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dutch-stable",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_type= [\"l1\"]\n",
    "learning_rate= [0.001,0.0001]\n",
    "momentum = [0.9]\n",
    "reg = [0.01]\n",
    "batch_size= [10]\n",
    "\n",
    "all_training_loss, all_validation_loss= hp_grid_search(model_type= \"SimpleCNN\", \n",
    "               lr_list=learning_rate, \n",
    "               momentum_list=momentum, \n",
    "               reg_list=reg, \n",
    "               batch_size_list=batch_size,\n",
    "               train_ds= train_ds,\n",
    "               valid_ds= valid_ds,\n",
    "               optimizer= optimizer, \n",
    "               loss_type_list=loss_type,\n",
    "               epochs= 10,\n",
    "               save_all_plots=\"Yes\", \n",
    "               save_final_plot=\"Yes\",\n",
    "               final_plot_prefix=\"Test\", \n",
    "               return_all_loss= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earned-greece",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}